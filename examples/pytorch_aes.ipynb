{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fit and analyze autoencoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from behavenet import get_user_dir, make_dir_if_not_exists\n",
    "from behavenet.fitting.utils import get_expt_dir\n",
    "from behavenet.fitting.utils import get_session_dir\n",
    "from behavenet.fitting.utils import get_best_model_version\n",
    "from behavenet.fitting.utils import get_lab_example\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "save_outputs = True  # true to save figures/movies to user's figure directory\n",
    "format = 'png'  # figure format ('png' | 'jpeg' | 'pdf'); movies saved as mp4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from behavenet.models import load_data as ld\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "train_dataset = ld.ParquetDataset(get_user_dir('data'), data_type = \"image\", split=\"train\")\n",
    "val_dataset = ld.ParquetDataset(get_user_dir('data'), data_type =\"image\", split=\"val\")\n",
    "test_dataset = ld.ParquetDataset(get_user_dir('data'), data_type=\"image\", split=\"test\")\n",
    "\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "print(f'Data in train/validation/test: {len(train_dataset)}/{len(val_dataset)}/{len(test_dataset)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from pytorch_lightning import Trainer\n",
    "from behavenet.models import lightning_ae as ae\n",
    "\n",
    "\n",
    "# Initialize autoencoder with correct input shape\n",
    "autoencoder = ae.LightningAutoencoder(\n",
    "    input_channels=1,\n",
    "    input_height=140,\n",
    "    input_width=170,\n",
    "    latent_dim=9, \n",
    "    learning_rate=1e-4\n",
    ")\n",
    "\n",
    "# Initialize Trainer\n",
    "trainer = Trainer(\n",
    "    max_epochs=100,  # Adjust based on convergence\n",
    "    accelerator=\"gpu\" if torch.cuda.is_available() else \"cpu\",\n",
    "    log_every_n_steps=10\n",
    ")\n",
    "\n",
    "# Train model\n",
    "trainer.fit(autoencoder, train_dataloaders=train_loader, val_dataloaders=val_loader)\n",
    "\n",
    "# Save model\n",
    "#model_save_path = os.path.join(get_user_dir('models'), 'ae')\n",
    "#make_dir_if_not_exists(model_save_path)\n",
    "#autoencoder.save_checkpoint(model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot loss \n",
    "import matplotlib.pyplot as plt\n",
    "train_losses = autoencoder.train_losses\n",
    "val_losses = autoencoder.val_losses\n",
    "val_losses = val_losses[:-1]\n",
    "\n",
    "# Plot across epochs\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(range(1, len(train_losses) + 1), train_losses, label=\"Train Loss\", marker=\"o\")\n",
    "plt.plot(range(1, len(val_losses) + 1), val_losses, label=\"Validation Loss\", marker=\"s\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Loss Over Epochs\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check reconstructions on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a batch of test images\n",
    "test_batch = next(iter(test_loader))\n",
    "test_images = test_batch[0].to(autoencoder.device)\n",
    "\n",
    "# Forward pass through the autoencoder\n",
    "with torch.no_grad():\n",
    "    reconstructed_images = autoencoder(test_images)\n",
    "\n",
    "# Convert tensors to numpy for visualization\n",
    "test_images_np = test_images.cpu().numpy()\n",
    "reconstructed_images_np = reconstructed_images.cpu().numpy()\n",
    "\n",
    "# Plot original and reconstructed images side by side\n",
    "n_images = 5  # Number of images to visualize\n",
    "fig, axes = plt.subplots(2, n_images, figsize=(15, 5))\n",
    "\n",
    "for i in range(n_images):\n",
    "    axes[0, i].imshow(test_images_np[i, 0], cmap=\"gray\")  # Original\n",
    "    axes[0, i].axis(\"off\")\n",
    "    axes[1, i].imshow(reconstructed_images_np[i, 0], cmap=\"gray\")  # Reconstructed\n",
    "    axes[1, i].axis(\"off\")\n",
    "\n",
    "axes[0, 0].set_title(\"Original Images\")\n",
    "axes[1, 0].set_title(\"Reconstructed Images\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "mse_loss = F.mse_loss(reconstructed_images, test_images)\n",
    "print(f\"Mean Squared Error (MSE): {mse_loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.metrics import structural_similarity as ssim\n",
    "import numpy as np\n",
    "\n",
    "# Compute SSIM for a batch\n",
    "ssim_values = []\n",
    "for i in range(test_images_np.shape[0]):\n",
    "    ssim_value = ssim(test_images_np[i, 0], reconstructed_images_np[i, 0], data_range=1.0)\n",
    "    ssim_values.append(ssim_value)\n",
    "\n",
    "print(f\"Average SSIM: {np.mean(ssim_values):.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "behavenet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
